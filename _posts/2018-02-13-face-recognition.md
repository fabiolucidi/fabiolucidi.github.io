---
layout: post
categories: privacy security
share: false
image:
  path: images/2018-02-13-face-recognition.jpg
  thumbnail: images/2018-02-13-face-recognition.jpg
  caption: "Testa di Moro"
title: "Face Recognition"
excerpt: "Alla fine è diventato di casa: lo abbiamo prima osservato, poi ci abbiamo giocato assieme – talvolta prendendolo in giro – ed infine lo abbiamo adottato. Il riconoscimento facciale è diventato carta canusciut’ o almeno così ci pare. Il processo di adozione non è stato veloce, ma sicuramente è stato inesorabile: uno schiacciasassi, un attacco a tenaglia che ci ha presi – e continuerà a prenderci – da diversi fronti...."
---
Alla fine è diventato di casa: lo abbiamo prima osservato, poi ci abbiamo giocato assieme – talvolta prendendolo in giro – ed infine lo abbiamo adottato. Il riconoscimento facciale è diventato _carta canusciut’_ o almeno così ci pare. Il processo di adozione non è stato veloce, ma sicuramente è stato inesorabile: uno schiacciasassi, un attacco a tenaglia che ci ha presi – e continuerà a prenderci – da diversi fronti.

Dopo diversi tentativi nel campo della _biometrica_ applicata alla sicurezza pare che la _face recognition_ sia la chiave più sicura per sbloccare i nostri lucchetti più importanti: iPhone X è solo l’ultimo esempio in ordine di tempo, ma probabilmente il migliore in termini di usabilità. Lo si guarda e il telefono si sblocca: come l’impronta digitale, ma senza la necessità di un lettore ad hoc. A dirla tutta non è l’ultima frontiera della sicurezza tramite biometrica, anzi è stata l’evoluzione di un processo iniziato diversi anni fa.

Ve la ricordate l’antica prassi di mettere data/luogo dietro le foto e soprattutto di segnarsi i nomi delle persone ritratte?
{: .notice--warning}

L’inizio è stato così lento da risultare impercettibile. Siamo passati dal doverci mettere in posa per non sprecare inutilmente 35mm di pellicola al fare foto a raffica per garantirci almeno uno scatto decente da mandare in pasto a Facebook – o ai vari software di gestione foto – per vederci poi spuntare i suggerimenti dei nomi dei volti e vede le nostre foto infilzate su una mappa. Inizialmente le associazioni proposte erano grossolane, ma la missione che ci veniva data pareva unica e irresistibile: taggare tutti, taggare sempre e soprattutto taggare per primi. Sembra ieri, ma era il 2011 e avevamo appena deciso di far fare ai software il salto dalla linea dei tiri liberi: **non più face detection, ma face recognition**.

Da un certo punto di vista si potrebbe dire che abbiamo donato il nostro volto alla scienza…
{: .notice--warning}

Così, con la più vincente gamification che si ricordi, abbiamo iniziato a dare ai vari software di riconoscimento facciale un sacco di suggerimenti gratuiti (per loro) e preziosissimi (per entrambi), incuranti della fine che avrebbero potuto fare le foto di quelle facce. E in effetti se vi state chiedendo cosa ha fatto facebook con queste foto la risposta probabilmente sarà “niente di male”: ha studiato. Il tempo, l’affinamento delle tecnologie, l’aumento del desiderio di sicurezza e tutto ciò che contiene la parola _custom_ hanno fatto il resto.

Perché i nostri dati personali, alla fine, non ci interessano granché?
{: .notice--warning}

Siamo abituati a preoccuparci della privacy come ad un tema strettamente personale il cui danno maggiore può essere _solo_ la violazione – senza o con divulgazione – di informazioni che riteniamo riservate. Non siamo invece abituati – non avendo vissuto epoche simili – a pensare alla privacy come ad un diritto che ci permette una difesa corretta da atti di violenza, fisica o meno, da parte di soggetti più potenti o motivati del singolo cittadino: uno stalker, associazioni, imprese, rami o poteri del nostro Stato o di altri Stati.

Nel quotidiano, per diversi motivi, non diamo minimamente peso se il sito dove acquistiamo prodotti vuole conservarsi le informazioni sulle nostre preferenze di acquisto per poterci consigliare prodotti più interessanti, ma non siamo neanche abituati a pensare che se qualcuno trafugasse al nostro amato sito (o se questo vendesse) quelle informazioni ad un terzo soggetto – chiamiamolo [I nazisti dell’Illinois](https://www.youtube.com/watch?v=ulCw7RJ5eE8) – potrebbe dedurre, per esempio, il nostro orientamento sessuale, politico o religioso e agire di conseguenza. Ad andar bene ci potrebbe inviare le mail con i dettagli del prossimo [Pride](http://www.gaypridecalendar.com/) o della prossima [Giornata mondiale della Gioventù](https://it.wikipedia.org/wiki/Giornata_mondiale_della_giovent%C3%B9_2019), ad andar male potrebbero venire a [prenderci a casa](http://www.anpi.it/articoli/1432/la-feroce-tecnica-dei-rastrellamenti-nazifascisti) con inedita precisione.

In che modo questo c’entra con il riconoscimento facciale?
{: .notice--warning}

Di per sé la face recognition è, come ogni tecnologia, neutrale, uno strumento per realizzare un obiettivo: questo porta con sé una serie di vantaggi e di rischi. La FR ha però una differenza sostanziale da tutte le forme di riconoscimento che fin qui ci sono state messe a disposizione: **non richiede il permesso dell’interessato**.

Al tempo della [strage di San Bernardino](https://en.wikipedia.org/wiki/2015_San_Bernardino_attack) avevo pensato che se il terrorista avesse avuto un telefono con lo sblocco tramite impronta digitale sarebbe stato [tutto molto più semplice](https://en.wikipedia.org/wiki/2015_San_Bernardino_attack#Phone_decryption): sarebbe bastato appoggiare il dito sul sensore e il problema dell’accesso sarebbe stato risolto. Questa riflessione da quattro soldi fu sufficiente per concludere che l’impronta digitale è un esempio di un’informazione difficile da proteggere (il che la rende una pessima password ancorchè molto affidabile, meglio di “1234” per capirsi).

Ecco, il riconoscimento facciale è basato su un’informazione **impossibile** da proteggere (il volto) e quindi alla mercé di chiunque abbia un _lettore_ adatto.

<figure class="align-center">
  <a href="#"><img src="{{ '/images/2018-02-13-face-recognition-banksy-wayla.jpg' | absolute_url }}" alt=""></a>
  <figcaption><i>Banksy - What are you looking at?</i></figcaption>
</figure>

Senza che nessuno ci chieda il permesso potremmo essere “analizzati” mentre siamo in aeroporto o allo stadio o al cinema (per i più diversi motivi). Qualcuno – un singolo come un’impresa – potrebbe usare la FR per capire la nostra provenienza, alcuni prodotti o servizi potrebbero venire erogati solo a persone con un determinato tipo di viso o ad un determinato prezzo in virtù del viso che guarda il prodotto, si potrebbero calcolare le probabilità di appartenere ad una determinata etnia o minoranza e _discriminare_ di conseguenza, potremmo essere rintracciati con imbarazzante semplicità dalle telecamere delle Autorità di Pubblica Sicurezza. Ma gli esempi sono smisurati, qualche volta angoscianti e talvolta addirittura già reali: [quest’articolo](https://www.ft.com/content/4707f246-a760-11e7-93c5-648314d2c72c) ne riassume molto bene alcuni e racconta di come in Cina la polizia già adotta soluzioni del genere per riconoscere (e arrestare) dei ricercati nella folla.

Ma le cose non sempre vanno bene, ci sono casi più kafkiani di persone tratte in arresto perché il [software di FR li scambia per un ricercato](https://irlpodcast.org/episode10/?sample_rate=0.001&utm_campaign=IRL10&snippet_name=7821&utm_medium=snippet&utm_content=7821), con tutte le conseguenze del caso.
Non propriamente il futuro che vorremmo: ci sono alternative?
